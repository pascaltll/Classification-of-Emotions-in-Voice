# Data paths
data:
  train_dir: data/ravdess/train
  val_dir: data/ravdess/val
  sample_rate: 16000
  max_length: 5.0  # Max audio length in seconds
  n_mels: 128      # Number of mel bins for CNN baseline

# Model settings
model:
  save_path: models/wav2vec2-emotion  # Path to save Wav2Vec2 model
  cnn_save_path: models/cnn_model     # Path to save CNN model
  hybrid_save_path: models/hybrid_model
  
# Training hyperparameters
training:
  lr: 1e-5          # Learning rate (suitable for Wav2Vec2 fine-tuning)
  batch_size: 64     # Batch size for training and evaluation
  epochs: 50        # Number of training epochs
  seed: 42          # Random seed for reproducibility

# Wandb configuration
wandb:
  project: Classification-of-Emotions-in-Voice  
  entity: tuesta-lx-moscow-institute-of-physics-and-technology     
  log_freq: 10                    # Frequency of logging to wandb

hydra:
  job:
    chdir: False