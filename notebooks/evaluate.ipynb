{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab8a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: neutral\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_path = \"../models/wav2vec2-emotion\"\n",
    "\n",
    "# Cargar procesador y modelo\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Ejemplo: preprocesar un archivo de audio y predecir\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "audio_input, sr = sf.read(\"../data/test_data/03-01-01-01-01-01-01.wav\")\n",
    "\n",
    "# Procesar audio (recuerda que debe coincidir la frecuencia de muestreo)\n",
    "inputs = processor(audio_input, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(f\"Predicción: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e0f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3810\n",
      "Precision: 0.3372\n",
      "Recall: 0.3810\n",
      "F1 Score: 0.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/Carlos/fine_tunig_project/segundo_entorno/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import soundfile as sf\n",
    "\n",
    "model_path = \"../models/wav2vec2-emotion\"\n",
    "test_dir = \"../data/test_data\"\n",
    "\n",
    "# Map de IDs a emociones (igual que en entrenamiento)\n",
    "id2emotion = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprise'\n",
    "}\n",
    "\n",
    "# Cargar modelo y procesador\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Función para extraer etiqueta real del nombre del archivo\n",
    "def extract_label(filename):\n",
    "    parts = filename.split('-')\n",
    "    emotion_id = parts[2]\n",
    "    return id2emotion.get(emotion_id)\n",
    "\n",
    "# Listar archivos test\n",
    "files = [f for f in os.listdir(test_dir) if f.endswith('.wav')]\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for f in files:\n",
    "    # Leer audio\n",
    "    audio_path = os.path.join(test_dir, f)\n",
    "    audio_input, sr = sf.read(audio_path)\n",
    "\n",
    "    # Procesar entrada\n",
    "    inputs = processor(audio_input, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "    true_label = extract_label(f)\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(predicted_label)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0fade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42417/3105666963.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(cfg.cnn_save_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2321\n",
      "Test Precision: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/Carlos/fine_tunig_project/segundo_entorno/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Añadir ruta para importar tu script\n",
    "import sys\n",
    "import os\n",
    "scripts_path = os.path.abspath(\"../scripts\")\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from cnn_baseline import CNN, RAVDESSMelDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Configuraciones similares a las que usaste en entrenamiento\n",
    "class Config:\n",
    "    sample_rate = 16000\n",
    "    n_mels = 128\n",
    "    max_length = 5.0\n",
    "    batch_size = 16\n",
    "    cnn_save_path = \"../models/cnn_model/cnn_model.pth\"\n",
    "    test_dir = \"../data/test_data\"\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar modelo\n",
    "model = CNN(num_classes=8)\n",
    "model.load_state_dict(torch.load(cfg.cnn_save_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Dataset y dataloader test\n",
    "test_dataset = RAVDESSMelDataset(cfg.test_dir, cfg.sample_rate, cfg.n_mels, cfg.max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['input'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Métricas\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cba0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segundo_entorno",
   "language": "python",
   "name": "nombre_del_nuevo_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
